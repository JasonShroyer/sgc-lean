% ============================================================================
% APPENDIX E: AUXILIARY LEMMAS
% ============================================================================
% Technical lemmas moved here to streamline the main narrative.
% All results are formally verified in the referenced Lean files.
% ============================================================================

\section{Auxiliary Lemmas}
\label{sec:auxiliary}

This appendix collects standard technical results used in the main development. 
Each lemma is formally verified in the Lean 4 codebase.

% ----------------------------------------------------------------------------
\subsection{Heat Kernel Differentiability}
\label{sec:aux:heat-kernel}
% ----------------------------------------------------------------------------

The following lemmas establish the differentiability properties of heat kernel 
observables required for the Functorial Heat Dominance Theorem (Section~\ref{sec:kinematics}).

\begin{lemma}[Heat Kernel Diagonal Differentiability]
\label{lem:aux-HeatKernel-diag-differentiable}
\leanlink{UPAT/Stability/Defs.lean}

The heat kernel diagonal $t \mapsto K(t)_{xx}$ is differentiable in $t$.

\begin{proof}
Express $K(t)_{xx} = (K(t) \cdot e_x)_x$ where $e_x$ is the standard basis vector at $x$.
By \texttt{HeatKernel\_coord\_differentiable}, coordinatewise differentiability holds.
\end{proof}
\end{lemma}

\begin{lemma}[Derivative of Heat Kernel Diagonal]
\label{lem:aux-deriv-HeatKernel-diag}
\leanlink{UPAT/Stability/Defs.lean}

\[
\frac{d}{dt} K(t)_{xx} = (L \cdot K(t))_{xx}
\]

\begin{proof}
By \texttt{heat\_semigroup\_deriv}: $\frac{d}{dt}(K(t) \cdot g) = L \cdot (K(t) \cdot g)$.
Apply to basis vector $e_x$ and extract coordinate $x$.
\end{proof}
\end{lemma}

\begin{lemma}[Derivative of Normalized Return Probability]
\label{lem:aux-deriv-K-norm}
\leanlink{UPAT/Stability/Defs.lean}

Given $\pi_x > 0$:
\[
\frac{d}{dt} \widetilde{K}(t, x) = -\frac{(L \cdot K(t))_{xx}}{\pi_x}
\]

\begin{proof}
By definition $\widetilde{K}(t,x) = 1 - K(t)_{xx}/\pi_x$.
Differentiate: $\frac{d}{dt}\widetilde{K} = 0 - \frac{1}{\pi_x}\frac{d}{dt}K(t)_{xx}$.
By Lemma~\ref{lem:aux-deriv-HeatKernel-diag}: $= -\frac{(L \cdot K(t))_{xx}}{\pi_x}$.
\end{proof}
\end{lemma}

% ----------------------------------------------------------------------------
\subsection{Probability and Conditional Expectation}
\label{sec:aux:probability}
% ----------------------------------------------------------------------------

The following lemmas establish basic properties of surprise and conditional 
expectation used in the Doob-Meyer decomposition (Section~\ref{sec:vitality}).

\begin{lemma}[Surprise Non-Negativity]
\label{lem:aux-surprise-nonneg}
\leanlink{UPAT/Vitality/DoobMeyer.lean}

Given $\sum_x \pi_x = 1$:
\[
\forall x,\quad \Phi(x) = -\log \pi_x \ge 0
\]

\begin{proof}
Since $\sum_y \pi_y = 1$ and $\pi_x > 0$, we have $\pi_x \le 1$.
Therefore $\log \pi_x \le 0$, so $-\log \pi_x \ge 0$.
\end{proof}
\end{lemma}

\begin{lemma}[Linearity of Conditional Expectation]
\label{lem:aux-condExp-linear}
\leanlink{UPAT/Vitality/DoobMeyer.lean}

\begin{align}
\mathbb{E}[(f + g)(X') \mid X = x] &= \mathbb{E}[f(X') \mid X = x] + \mathbb{E}[g(X') \mid X = x] \\
\mathbb{E}[(c \cdot f)(X') \mid X = x] &= c \cdot \mathbb{E}[f(X') \mid X = x]
\end{align}

\begin{proof}
By \texttt{sum\_add\_distrib} and \texttt{mul\_left\_comm} respectively.
\end{proof}
\end{lemma}

\begin{lemma}[Expectation of Constants]
\label{lem:aux-condExp-const}
\leanlink{UPAT/Vitality/DoobMeyer.lean}

For stochastic $P$:
\[
\mathbb{E}[1 \mid X = x] = 1, \qquad \mathbb{E}[c \mid X = x] = c
\]

\begin{proof}
$\sum_y P_{xy} \cdot 1 = \sum_y P_{xy} = 1$ by the stochastic property.
\end{proof}
\end{lemma}

% ----------------------------------------------------------------------------
\subsection{Extropic Potential Bounds}
\label{sec:aux:extropy}
% ----------------------------------------------------------------------------

The following lemmas establish bounds on the extropic potential used in 
the Least Action principle (Section~\ref{sec:kinetics}).

\begin{lemma}[Extropy Positivity]
\label{lem:aux-extropic-pos}
\leanlink{UPAT/Kinetics/LeastAction.lean}

For $\pi_x > 0$:
\[
\Psi(x) = \pi_x > 0
\]

\begin{proof}
Direct from the hypothesis $\pi_x > 0$.
\end{proof}
\end{lemma}

\begin{lemma}[Extropy Boundedness]
\label{lem:aux-extropic-bounded}
\leanlink{UPAT/Kinetics/LeastAction.lean}

For probability distributions with $\sum_x \pi_x = 1$:
\[
\Psi(x) = \pi_x \le 1
\]

\begin{proof}
$\pi_x \le \sum_y \pi_y = 1$.
\end{proof}
\end{lemma}

% ============================================================================
% END AUXILIARY LEMMAS
% ============================================================================
