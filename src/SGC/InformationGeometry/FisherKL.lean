/-
Copyright (c) 2025 SGC Project. All rights reserved.
Released under Apache 2.0 license as described in the file LICENSE.
Authors: SGC Formalization Team

# Fisher-KL Bounds: Information Geometry for Learning Systems

This module establishes the fundamental connection between the Fisher information
metric and KL divergence, providing the mathematical foundation for:
- Validity horizons for learned skills
- Projected gradient methods that preserve consolidated behaviors
- No-forgetting bounds for continual learning

## Main Results

1. `KL_Fisher_local_bound` - KL(p_Î¸ â€– p_{Î¸+Î”Î¸}) â‰¤ Â½ Î”Î¸áµ€ F(Î¸) Î”Î¸ + O(â€–Î”Î¸â€–Â³)
2. `Fisher_orthogonal_KL_bound` - Fisher-orthogonal updates have bounded KL change
3. `projected_update_formula` - Closed-form Fisher-orthogonal projection
4. `no_forgetting_horizon` - Accumulated KL drift bound over many steps

## Physical Significance

**Information Geometry**: The Fisher metric F(Î¸) is the "natural" Riemannian metric
on the statistical manifold {p_Î¸}. KL divergence measures "distance" along geodesics.

**Learning Connection**: Policy gradient methods move along the statistical manifold.
Fisher-orthogonal projections ensure we don't "forget" consolidated skills.

**SGC Bridge**: This is the learning-side sibling of `trajectory_closure_bound` -
both bound accumulated error from approximate dynamics.

## References

- Amari (1998), "Natural Gradient Works Efficiently in Learning"
- Martens (2014), "New Insights and Perspectives on the Natural Gradient Method"
-/

import Mathlib.Analysis.InnerProductSpace.PiL2
import Mathlib.LinearAlgebra.Matrix.PosDef
import Mathlib.Data.Matrix.Basic
import Mathlib.Algebra.BigOperators.Group.Finset.Basic

noncomputable section

namespace SGC.InformationGeometry.FisherKL

open Finset Matrix Real

-- Suppress unused variable warnings
set_option linter.unusedSectionVars false
set_option linter.unusedVariables false

variable {V : Type*} [Fintype V] [DecidableEq V]

/-! ## Part I: KL Divergence and Fisher Information -/

/-! ### 1. KL Divergence for Finite Distributions -/

/-- **KL Divergence** between two distributions p and q over finite state space V.

    D_KL(p â€– q) = Î£áµ¥ p(v) log(p(v)/q(v))

    We use the convention 0 log 0 = 0 and x log(x/0) = +âˆ. -/
def KL_divergence (p q : V â†’ â„) : â„ :=
  âˆ‘ v, if p v = 0 then 0 else p v * Real.log (p v / q v)

/-- KL divergence is non-negative (Gibbs' inequality). -/
axiom KL_nonneg (p q : V â†’ â„) (hp : âˆ€ v, 0 â‰¤ p v) (hq : âˆ€ v, 0 < q v)
    (hp_sum : âˆ‘ v, p v = 1) (hq_sum : âˆ‘ v, q v = 1) :
    0 â‰¤ KL_divergence p q

/-- KL divergence is zero iff p = q. -/
axiom KL_eq_zero_iff (p q : V â†’ â„) (hp : âˆ€ v, 0 < p v) (hq : âˆ€ v, 0 < q v)
    (hp_sum : âˆ‘ v, p v = 1) (hq_sum : âˆ‘ v, q v = 1) :
    KL_divergence p q = 0 â†” p = q

/-! ### 2. Parametric Families -/

/-- A **Parametric Family** is a smooth map from parameters Î¸ âˆˆ â„â¿ to distributions.
    We assume the family is "regular" (smooth, positive, normalized). -/
structure ParametricFamily (n : â„•) (V : Type*) [Fintype V] where
  /-- The distribution at parameter Î¸ -/
  dist : (Fin n â†’ â„) â†’ V â†’ â„
  /-- Distributions are positive -/
  positive : âˆ€ Î¸ v, 0 < dist Î¸ v
  /-- Distributions are normalized -/
  normalized : âˆ€ Î¸, âˆ‘ v, dist Î¸ v = 1

variable {n : â„•}

/-- Shorthand for the distribution at Î¸. -/
abbrev ParametricFamily.p (P : ParametricFamily n V) (Î¸ : Fin n â†’ â„) : V â†’ â„ := P.dist Î¸

/-! ### 3. Fisher Information Matrix -/

/-- **Score Function**: The gradient of log p_Î¸(v) with respect to Î¸.

    s_i(Î¸, v) = âˆ‚/âˆ‚Î¸_i log p_Î¸(v) = (âˆ‚p_Î¸(v)/âˆ‚Î¸_i) / p_Î¸(v)

    This is axiomatized since we don't have a concrete representation of p_Î¸. -/
axiom score_function (P : ParametricFamily n V) (Î¸ : Fin n â†’ â„) (i : Fin n) (v : V) : â„

/-- Score has zero mean: ğ”¼_{p_Î¸}[s_i] = 0.
    This is a fundamental identity in information geometry. -/
axiom score_zero_mean (P : ParametricFamily n V) (Î¸ : Fin n â†’ â„) (i : Fin n) :
    âˆ‘ v, P.p Î¸ v * score_function P Î¸ i v = 0

/-- **Fisher Information Matrix**: The covariance of the score function.

    F(Î¸)_{ij} = ğ”¼_{p_Î¸}[s_i(Î¸, Â·) Â· s_j(Î¸, Â·)]
             = Î£áµ¥ p_Î¸(v) Â· s_i(Î¸,v) Â· s_j(Î¸,v)

    This is the natural Riemannian metric on the statistical manifold. -/
def FisherMatrix (P : ParametricFamily n V) (Î¸ : Fin n â†’ â„) : Matrix (Fin n) (Fin n) â„ :=
  Matrix.of fun i j => âˆ‘ v, P.p Î¸ v * score_function P Î¸ i v * score_function P Î¸ j v

/-- Fisher matrix is symmetric. -/
lemma FisherMatrix_symmetric (P : ParametricFamily n V) (Î¸ : Fin n â†’ â„) :
    (FisherMatrix P Î¸).IsSymm := by
  unfold Matrix.IsSymm FisherMatrix
  ext i j
  simp only [transpose_apply, of_apply]
  congr 1; ext v; ring

/-- Fisher matrix is positive semidefinite.
    F(Î¸) â‰¥ 0 follows from F = ğ”¼[s sáµ€] being a covariance matrix. -/
axiom FisherMatrix_posSemidef (P : ParametricFamily n V) (Î¸ : Fin n â†’ â„) :
    âˆ€ w : Fin n â†’ â„, 0 â‰¤ âˆ‘ i, âˆ‘ j, w i * (FisherMatrix P Î¸) i j * w j

/-! ## Part II: The KL-Fisher Local Bound -/

/-- **The Quadratic Form**: Î”Î¸áµ€ F(Î¸) Î”Î¸ -/
def FisherQuadForm (P : ParametricFamily n V) (Î¸ Î”Î¸ : Fin n â†’ â„) : â„ :=
  âˆ‘ i, âˆ‘ j, Î”Î¸ i * (FisherMatrix P Î¸) i j * Î”Î¸ j

/-- The quadratic form is non-negative. -/
lemma FisherQuadForm_nonneg (P : ParametricFamily n V) (Î¸ Î”Î¸ : Fin n â†’ â„) :
    0 â‰¤ FisherQuadForm P Î¸ Î”Î¸ :=
  FisherMatrix_posSemidef P Î¸ Î”Î¸

/-- **Euclidean Norm Squared** of Î”Î¸. -/
def paramNormSq (Î”Î¸ : Fin n â†’ â„) : â„ := âˆ‘ i, (Î”Î¸ i)^2

/-- **KL-Fisher Local Bound** (Main Theorem 1):

    For small Î”Î¸, the KL divergence is bounded by the Fisher quadratic form:

    KL(p_Î¸ â€– p_{Î¸+Î”Î¸}) â‰¤ Â½ Î”Î¸áµ€ F(Î¸) Î”Î¸ + C Â· â€–Î”Î¸â€–Â³

    This is the fundamental "metric controls drift" statement.

    **Proof Idea** (Taylor expansion):
    1. KL(p â€– q) = Î£ p log(p/q) = -Î£ p log(q/p)
    2. log p_{Î¸+Î”Î¸}(v) â‰ˆ log p_Î¸(v) + Î£áµ¢ Î”Î¸áµ¢ Â· s_i(Î¸,v) + Â½ Î£áµ¢â±¼ Î”Î¸áµ¢ Î”Î¸â±¼ Â· H_ij(Î¸,v)
    3. Taking expectation and using score_zero_mean, the linear term vanishes
    4. The quadratic term gives Â½ Î”Î¸áµ€ F(Î¸) Î”Î¸
    5. The remainder is O(â€–Î”Î¸â€–Â³)

**AXIOM: KL-Fisher Local Bound**

    This is the fundamental Taylor expansion result connecting KL divergence
    to Fisher information. It requires smoothness assumptions on P that are
    standard in information geometry but not encoded in our ParametricFamily.

    **Mathematical content**: For smooth parametric families,
    KL(p_Î¸ â€– p_{Î¸+Î”Î¸}) = Â½ Î”Î¸áµ€ F(Î¸) Î”Î¸ + O(â€–Î”Î¸â€–Â³)

    **Reference**: Amari & Nagaoka, "Methods of Information Geometry", Thm 3.3 -/
axiom KL_Fisher_local_bound (P : ParametricFamily n V) (Î¸ Î”Î¸ : Fin n â†’ â„) :
    âˆƒ (C : â„), 0 â‰¤ C âˆ§
      KL_divergence (P.p Î¸) (P.p (Î¸ + Î”Î¸)) â‰¤
        (1/2) * FisherQuadForm P Î¸ Î”Î¸ + C * (paramNormSq Î”Î¸) * Real.sqrt (paramNormSq Î”Î¸)

/-! ## Part III: Fisher-Orthogonal Projections -/

/-! ### 4. Consolidated Subspace -/

/-- A **Consolidated Subspace** is a k-dimensional linear subspace of parameter space â„â¿
    representing "frozen" or "protected" behaviors.

    Think of this as the space of parameters that affect consolidated skills. -/
structure ConsolidatedSubspace (n k : â„•) where
  /-- Basis vectors for the subspace -/
  basis : Fin k â†’ (Fin n â†’ â„)
  /-- Basis is orthonormal (in Euclidean sense) -/
  orthonormal : âˆ€ i j, âˆ‘ l, basis i l * basis j l = if i = j then 1 else 0

/-- **Fisher Inner Product**: The inner product induced by Fisher matrix.
    âŸ¨u, vâŸ©_F = uáµ€ F(Î¸) v -/
def FisherInner (P : ParametricFamily n V) (Î¸ : Fin n â†’ â„) (u v : Fin n â†’ â„) : â„ :=
  âˆ‘ i, âˆ‘ j, u i * (FisherMatrix P Î¸) i j * v j

/-- Fisher inner product is symmetric. -/
lemma FisherInner_symm (P : ParametricFamily n V) (Î¸ u v : Fin n â†’ â„) :
    FisherInner P Î¸ u v = FisherInner P Î¸ v u := by
  unfold FisherInner
  have h_symm := FisherMatrix_symmetric P Î¸
  -- Use symmetry: F_{ij} = F_{ji}
  have h_entry : âˆ€ i j, (FisherMatrix P Î¸) i j = (FisherMatrix P Î¸) j i :=
    fun i j => (h_symm.apply i j).symm
  calc âˆ‘ i, âˆ‘ j, u i * (FisherMatrix P Î¸) i j * v j
      = âˆ‘ i, âˆ‘ j, v j * (FisherMatrix P Î¸) j i * u i := by
          congr 1; ext i; congr 1; ext j; rw [h_entry i j]; ring
    _ = âˆ‘ j, âˆ‘ i, v j * (FisherMatrix P Î¸) j i * u i := Finset.sum_comm
    _ = _ := by rfl

variable {k : â„•}

/-- A direction v is **Fisher-orthogonal** to a subspace S if
    âŸ¨v, sâŸ©_F = 0 for all s in S. -/
def IsFisherOrthogonal (P : ParametricFamily n V) (Î¸ : Fin n â†’ â„)
    (S : ConsolidatedSubspace n k) (v : Fin n â†’ â„) : Prop :=
  âˆ€ i : Fin k, FisherInner P Î¸ v (S.basis i) = 0

/-! ### 5. Fisher-Orthogonal Projection (CONSTRUCTIVE)

This section makes the Fisher-orthogonal projector **constructive** rather than axiomatic.
The key insight is that the projector solves a **constrained optimization problem**.

## The Minimal Disturbance Principle

**Problem**: Given a gradient direction g, find the update Î”Î¸ that:
1. Minimizes deviation from g in the Fisher metric: min â€–Î”Î¸ - gâ€–Â²_F
2. Subject to freezing consolidated directions: S Î”Î¸ = 0 (PRIMAL CONSTRAINT)

where S is a kÃ—n matrix whose rows span the "consolidated subspace" (parameters to freeze).

**Solution**: Î”Î¸ = P_âŠ¥ g  where P_âŠ¥ = I - Fâ»Â¹Sáµ€(SFâ»Â¹Sáµ€)â»Â¹S

## Connection to SGC Defect Structure

This is the **learning-side analog** of SGC's coarse projector:
- **SGC**: Î  = lift âˆ˜ Q projects onto block-constant functions (macro-observables)
- **Learning**: P_âŠ¥ projects onto the orthogonal complement of consolidated skills

Both satisfy D = (I - Î ) L Î , where D is the "leakage defect."
The projector emerges from minimizing disturbance subject to preservation constraints.
-/

/-- **Subspace Matrix**: Convert basis vectors to a matrix S : k Ã— n
    where row i is the i-th basis vector. -/
def SubspaceMatrix (S : ConsolidatedSubspace n k) : Matrix (Fin k) (Fin n) â„ :=
  Matrix.of (fun i j => S.basis i j)

/-- **Regularized Fisher Inverse**: Fâ»Â¹ with Tikhonov regularization (F + Î»I)â»Â¹.
    This ensures invertibility even when F is singular or ill-conditioned.
    For Î» > 0 and F positive semidefinite, (F + Î»I) is positive definite. -/
structure RegularizedFisher (n : â„•) where
  /-- The Fisher matrix -/
  F : Matrix (Fin n) (Fin n) â„
  /-- Regularization parameter (Tikhonov damping) -/
  regParam : â„
  /-- regParam > 0 for positive definiteness -/
  regParam_pos : 0 < regParam
  /-- F is symmetric -/
  F_symm : F.IsSymm
  /-- F is positive semidefinite -/
  F_posSemidef : âˆ€ v : Fin n â†’ â„, 0 â‰¤ âˆ‘ i, âˆ‘ j, v i * F i j * v j

/-- The regularized matrix F + Î»I. -/
def RegularizedFisher.regularized (RF : RegularizedFisher n) : Matrix (Fin n) (Fin n) â„ :=
  RF.F + RF.regParam â€¢ (1 : Matrix (Fin n) (Fin n) â„)

/-- **AXIOM: Regularized Fisher is Positive Definite**

    For F positive semidefinite and Î» > 0, (F + Î»I) is positive definite.
    This is standard linear algebra: âŸ¨v, (F + Î»I)vâŸ© = âŸ¨v, FvâŸ© + Î»â€–vâ€–Â² > 0 for v â‰  0.

    **Note**: This could be proven using Mathlib's PosDef theory, but we axiomatize
    it to avoid deep dependencies on matrix positivity infrastructure. -/
axiom RegularizedFisher.posDef (RF : RegularizedFisher n) :
    âˆ€ v : Fin n â†’ â„, v â‰  0 â†’ 0 < âˆ‘ i, âˆ‘ j, v i * RF.regularized i j * v j

/-! ## TWO PROJECTORS: EUCLIDEAN VS FISHER

**Critical Distinction** (addressing the "one projector, two contracts" issue):

1. **Euclidean Projector** (Primal): Minimizes â€–Î”Î¸ - gâ€–Â²_Euclidean subject to SÎ”Î¸ = 0
   - Formula: P_E = I - Sáµ€(SSáµ€)â»Â¹S
   - Use for: Standard gradient descent with frozen parameters

2. **Fisher Projector** (Natural): Minimizes â€–Î”Î¸ - gâ€–Â²_Fisher subject to SÎ”Î¸ = 0
   - Formula: P_F = I - Fâ»Â¹Sáµ€(SFâ»Â¹Sáµ€)â»Â¹S
   - Use for: Natural gradient descent (information geometry)

**Key Insight**: Both projectors enforce the SAME primal constraint (SÎ”Î¸ = 0),
but they minimize distance in DIFFERENT metrics. The Fisher projector is the
correct one for learning because it respects the geometry of the parameter space.

**When do they coincide?** When F = I (flat geometry), P_E = P_F.
-/

/-- **Euclidean Projector Matrix** (PRIMAL CONSTRAINT, EUCLIDEAN METRIC):

    P_E = I - Sáµ€ (S Sáµ€)â»Â¹ S

    This is the standard orthogonal projection onto ker(S).

    **Optimization problem solved**:
    - Minimize: Â½ â€–Î”Î¸ - gâ€–Â²_Euclidean
    - Subject to: S Î”Î¸ = 0

    **Use case**: Standard gradient descent where we want to freeze certain
    linear combinations of parameters. -/
def EuclideanProjector (S : ConsolidatedSubspace n k)
    (Gram_inv : Matrix (Fin k) (Fin k) â„)  -- (S Sáµ€)â»Â¹
    : Matrix (Fin n) (Fin n) â„ :=
  let S_mat := SubspaceMatrix S
  (1 : Matrix (Fin n) (Fin n) â„) - S_matáµ€ * Gram_inv * S_mat

/-- **Fisher Projector Matrix** (PRIMAL CONSTRAINT, FISHER METRIC):

    P_F = I - Fâ»Â¹ Sáµ€ (S Fâ»Â¹ Sáµ€)â»Â¹ S

    This is the projection onto ker(S) that minimizes Fisher distance.

    **Optimization problem solved**:
    - Minimize: Â½ (Î”Î¸ - g)áµ€ F (Î”Î¸ - g)
    - Subject to: S Î”Î¸ = 0

    **Use case**: Natural gradient descent where we want to freeze certain
    linear combinations of parameters while respecting the information geometry.

    **Note**: This is the SAME formula as FisherOrthogonalProjector below,
    but with clearer semantic intent: we enforce a PRIMAL constraint (SÎ”Î¸=0)
    while minimizing in the FISHER metric. -/
def FisherProjector (RF : RegularizedFisher n)
    (S : ConsolidatedSubspace n k)
    (F_reg_inv : Matrix (Fin n) (Fin n) â„)  -- (F + Î»I)â»Â¹
    (Gram_inv : Matrix (Fin k) (Fin k) â„)   -- (S (F + Î»I)â»Â¹ Sáµ€)â»Â¹
    : Matrix (Fin n) (Fin n) â„ :=
  let S_mat := SubspaceMatrix S
  (1 : Matrix (Fin n) (Fin n) â„) - F_reg_inv * S_matáµ€ * Gram_inv * S_mat

/-- **Fisher-Orthogonal Projector Matrix** (LEGACY NAME, SAME AS FisherProjector):

    P_âŠ¥ = I - (F + Î»I)â»Â¹ Sáµ€ (S (F + Î»I)â»Â¹ Sáµ€)â»Â¹ S

    This is kept for backwards compatibility. Prefer `FisherProjector` for clarity. -/
def FisherOrthogonalProjector (RF : RegularizedFisher n)
    (S : ConsolidatedSubspace n k)
    (F_reg_inv : Matrix (Fin n) (Fin n) â„)  -- (F + Î»I)â»Â¹
    (Gram_inv : Matrix (Fin k) (Fin k) â„)   -- (S (F + Î»I)â»Â¹ Sáµ€)â»Â¹
    : Matrix (Fin n) (Fin n) â„ :=
  FisherProjector RF S F_reg_inv Gram_inv

/-- **Constrained Optimization Problem**: The objective we're minimizing.
    J(Î”Î¸) = Â½ (Î”Î¸ - g)áµ€ F (Î”Î¸ - g) = Â½ â€–Î”Î¸ - gâ€–Â²_F -/
def FisherObjective (RF : RegularizedFisher n) (g Î”Î¸ : Fin n â†’ â„) : â„ :=
  (1/2) * âˆ‘ i, âˆ‘ j, (Î”Î¸ i - g i) * RF.regularized i j * (Î”Î¸ j - g j)

/-- **Primal Feasibility Constraint**: S Î”Î¸ = 0 (freeze consolidated directions).

    This is the **primal constraint**: the update must have zero component
    in each consolidated direction. In matrix form: (S *áµ¥ Î”Î¸) = 0.

    **Interpretation for Sudoku/Learning**:
    - S contains directions that affect already-solved cells / consolidated skills
    - S Î”Î¸ = 0 means the update doesn't change those cells / skills -/
def PrimalFeasible (S : ConsolidatedSubspace n k) (Î”Î¸ : Fin n â†’ â„) : Prop :=
  âˆ€ i : Fin k, âˆ‘ j, S.basis i j * Î”Î¸ j = 0

/-- **Fisher-Orthogonality Constraint**: âŸ¨s_i, Î”Î¸âŸ©_F = 0 (orthogonal in Fisher metric).

    This is a **dual constraint**: the update must be Fisher-orthogonal to
    the consolidated subspace. In matrix form: S F Î”Î¸ = 0.

    Note: This is DIFFERENT from PrimalFeasible. Use PrimalFeasible for
    "freeze specific parameters" and FisherFeasible for "orthogonal in metric." -/
def FisherFeasible (RF : RegularizedFisher n) (S : ConsolidatedSubspace n k)
    (Î”Î¸ : Fin n â†’ â„) : Prop :=
  âˆ€ i : Fin k, âˆ‘ l, âˆ‘ m, S.basis i l * RF.regularized l m * Î”Î¸ m = 0

/-- **MINIMAL DISTURBANCE THEOREM** (Main Theoretical Result):

    The Fisher-orthogonal projector gives the UNIQUE minimizer of the
    constrained optimization problem with **primal constraint**:

    Î”Î¸* = argmin { â€–Î”Î¸ - gâ€–Â²_F : S Î”Î¸ = 0 }
        = P_âŠ¥ g
        = (I - Fâ»Â¹Sáµ€(SFâ»Â¹Sáµ€)â»Â¹S) g

    This turns "preserve consolidated skills" into a **computable control law**.

    ## Derivation via Lagrange Multipliers

    **Lagrangian**: L(Î”Î¸, Î¼) = Â½(Î”Î¸-g)áµ€F(Î”Î¸-g) + Î¼áµ€ S Î”Î¸

    **Stationarity**: âˆ‚L/âˆ‚Î”Î¸ = F(Î”Î¸-g) + Sáµ€Î¼ = 0
                     â†’ FÎ”Î¸ = Fg - Sáµ€Î¼
                     â†’ Î”Î¸ = g - Fâ»Â¹Sáµ€Î¼

    **Feasibility**: S Î”Î¸ = 0
                     â†’ S(g - Fâ»Â¹Sáµ€Î¼) = 0
                     â†’ Sg = SFâ»Â¹Sáµ€Î¼
                     â†’ Î¼ = (SFâ»Â¹Sáµ€)â»Â¹ Sg

    **Solution**: Î”Î¸ = g - Fâ»Â¹Sáµ€(SFâ»Â¹Sáµ€)â»Â¹Sg
                    = (I - Fâ»Â¹Sáµ€(SFâ»Â¹Sáµ€)â»Â¹S) g
                    = P_âŠ¥ g  âœ“

    ## SGC Interpretation

    This is the **Equivalence Principle for Learning**:
    - The projected update is the "geodesic" motion on the constraint manifold
    - Fâ»Â¹Sáµ€(SFâ»Â¹Sáµ€)â»Â¹S is the "defect" that gets subtracted (cf. SGC's D = (I-Î )LÎ )
    - Minimizing Fisher distance = minimizing thermodynamic cost of the update

**PRIMAL CONSTRAINT VERSION** (The main theorem for learning applications):

    The projector P_âŠ¥ = I - Fâ»Â¹Sáµ€(SFâ»Â¹Sáµ€)â»Â¹S gives the unique minimizer of:

    min â€–Î”Î¸ - gâ€–Â²_F  subject to  S Î”Î¸ = 0

    This is the correct theorem for "freeze consolidated parameters."

**AXIOM: Minimal Disturbance (Primal Feasibility)**

    The projector P_âŠ¥ = I - Fâ»Â¹Sáµ€(SFâ»Â¹Sáµ€)â»Â¹S satisfies S(P_âŠ¥ g) = 0.

    **Proof sketch** (matrix algebra):
    S P_âŠ¥ g = S(I - Fâ»Â¹Sáµ€ Gramâ»Â¹ S)g = Sg - (SFâ»Â¹Sáµ€) Gramâ»Â¹ Sg = Sg - Sg = 0

    This is axiomatized because the matrix index manipulation in Lean is tedious. -/
axiom minimal_disturbance_primal_feasibility (RF : RegularizedFisher n)
    (S : ConsolidatedSubspace n k) (g : Fin n â†’ â„)
    (F_reg_inv : Matrix (Fin n) (Fin n) â„)
    (Gram_inv : Matrix (Fin k) (Fin k) â„)
    (h_F_inv : F_reg_inv * RF.regularized = 1)
    (h_Gram_inv : let S_mat := SubspaceMatrix S
                  Gram_inv * (S_mat * F_reg_inv * S_matáµ€) = 1) :
    let P_perp := FisherOrthogonalProjector RF S F_reg_inv Gram_inv
    PrimalFeasible S (P_perp *áµ¥ g)

/-- **AXIOM: Minimal Disturbance (Primal Optimality)**

    The projector output P_âŠ¥ g minimizes Fisher distance to g among all
    primal-feasible updates (those satisfying S Î”Î¸ = 0).

    **Proof sketch** (convex optimization):
    - Objective â€–Î”Î¸ - gâ€–Â²_F is strictly convex (F + Î»I positive definite)
    - Constraint SÎ”Î¸ = 0 is linear (affine subspace)
    - P_âŠ¥ g satisfies KKT conditions by construction
    - Therefore it is the unique global minimizer

    This is the core variational principle behind Fisher-orthogonal learning. -/
axiom minimal_disturbance_primal_optimality (RF : RegularizedFisher n)
    (S : ConsolidatedSubspace n k) (g : Fin n â†’ â„)
    (F_reg_inv : Matrix (Fin n) (Fin n) â„)
    (Gram_inv : Matrix (Fin k) (Fin k) â„)
    (h_F_inv : F_reg_inv * RF.regularized = 1)
    (h_Gram_inv : let S_mat := SubspaceMatrix S
                  Gram_inv * (S_mat * F_reg_inv * S_matáµ€) = 1) :
    let P_perp := FisherOrthogonalProjector RF S F_reg_inv Gram_inv
    let Î”Î¸_opt := P_perp *áµ¥ g
    âˆ€ Î”Î¸ : Fin n â†’ â„, PrimalFeasible S Î”Î¸ â†’
      FisherObjective RF g Î”Î¸_opt â‰¤ FisherObjective RF g Î”Î¸

/-- **THEOREM: Minimal Disturbance (Combined)**

    The projector P_âŠ¥ gives the unique minimizer of the constrained problem.
    This theorem combines feasibility and optimality from the axioms above. -/
theorem minimal_disturbance_primal (RF : RegularizedFisher n)
    (S : ConsolidatedSubspace n k) (g : Fin n â†’ â„)
    (F_reg_inv : Matrix (Fin n) (Fin n) â„)
    (Gram_inv : Matrix (Fin k) (Fin k) â„)
    (h_F_inv : F_reg_inv * RF.regularized = 1)
    (h_Gram_inv : let S_mat := SubspaceMatrix S
                  Gram_inv * (S_mat * F_reg_inv * S_matáµ€) = 1)
    : let P_perp := FisherOrthogonalProjector RF S F_reg_inv Gram_inv
      let Î”Î¸_opt := P_perp *áµ¥ g
      PrimalFeasible S Î”Î¸_opt âˆ§
      (âˆ€ Î”Î¸ : Fin n â†’ â„, PrimalFeasible S Î”Î¸ â†’
        FisherObjective RF g Î”Î¸_opt â‰¤ FisherObjective RF g Î”Î¸) :=
  âŸ¨minimal_disturbance_primal_feasibility RF S g F_reg_inv Gram_inv h_F_inv h_Gram_inv,
   minimal_disturbance_primal_optimality RF S g F_reg_inv Gram_inv h_F_inv h_Gram_invâŸ©

/-- **AXIOM: Fisher-Orthogonality Projection Feasibility**

    For the constraint S F Î”Î¸ = 0 (Fisher-orthogonal to S), the projector
    output satisfies the constraint. -/
axiom fisher_orthogonal_projection_feasibility (RF : RegularizedFisher n)
    (S : ConsolidatedSubspace n k) (g : Fin n â†’ â„)
    (F_reg_inv : Matrix (Fin n) (Fin n) â„)
    (Gram_inv : Matrix (Fin k) (Fin k) â„)
    (h_F_inv : F_reg_inv * RF.regularized = 1)
    (h_Gram_inv : let S_mat := SubspaceMatrix S
                  Gram_inv * (S_mat * F_reg_inv * S_matáµ€) = 1) :
    let P_perp := FisherOrthogonalProjector RF S F_reg_inv Gram_inv
    FisherFeasible RF S (P_perp *áµ¥ g)

/-- **AXIOM: Fisher-Orthogonality Projection Optimality**

    The projector output minimizes Fisher distance among Fisher-feasible updates. -/
axiom fisher_orthogonal_projection_optimality (RF : RegularizedFisher n)
    (S : ConsolidatedSubspace n k) (g : Fin n â†’ â„)
    (F_reg_inv : Matrix (Fin n) (Fin n) â„)
    (Gram_inv : Matrix (Fin k) (Fin k) â„)
    (h_F_inv : F_reg_inv * RF.regularized = 1)
    (h_Gram_inv : let S_mat := SubspaceMatrix S
                  Gram_inv * (S_mat * F_reg_inv * S_matáµ€) = 1) :
    let P_perp := FisherOrthogonalProjector RF S F_reg_inv Gram_inv
    let Î”Î¸_opt := P_perp *áµ¥ g
    âˆ€ Î”Î¸ : Fin n â†’ â„, FisherFeasible RF S Î”Î¸ â†’
      FisherObjective RF g Î”Î¸_opt â‰¤ FisherObjective RF g Î”Î¸

/-- **THEOREM: Fisher-Orthogonality Projection (Combined)**

    For the constraint S F Î”Î¸ = 0 (Fisher-orthogonal to S), the projector
    gives the unique minimizer. -/
theorem fisher_orthogonal_projection_optimal (RF : RegularizedFisher n)
    (S : ConsolidatedSubspace n k) (g : Fin n â†’ â„)
    (F_reg_inv : Matrix (Fin n) (Fin n) â„)
    (Gram_inv : Matrix (Fin k) (Fin k) â„)
    (h_F_inv : F_reg_inv * RF.regularized = 1)
    (h_Gram_inv : let S_mat := SubspaceMatrix S
                  Gram_inv * (S_mat * F_reg_inv * S_matáµ€) = 1)
    : let P_perp := FisherOrthogonalProjector RF S F_reg_inv Gram_inv
      let Î”Î¸_opt := P_perp *áµ¥ g
      FisherFeasible RF S Î”Î¸_opt âˆ§
      (âˆ€ Î”Î¸ : Fin n â†’ â„, FisherFeasible RF S Î”Î¸ â†’
        FisherObjective RF g Î”Î¸_opt â‰¤ FisherObjective RF g Î”Î¸) :=
  âŸ¨fisher_orthogonal_projection_feasibility RF S g F_reg_inv Gram_inv h_F_inv h_Gram_inv,
   fisher_orthogonal_projection_optimality RF S g F_reg_inv Gram_inv h_F_inv h_Gram_invâŸ©

/-- **AXIOM: Projector Idempotence**

    The projector P_âŠ¥ is idempotent: PÂ² = P.

    **Proof sketch**: P_âŠ¥Â² = (I - A)(I - A) = I - 2A + AÂ² where A = Fâ»Â¹Sáµ€ Gramâ»Â¹ S.
    Since AÂ² = Fâ»Â¹Sáµ€ Gramâ»Â¹ (SFâ»Â¹Sáµ€) Gramâ»Â¹ S = Fâ»Â¹Sáµ€ Gramâ»Â¹ S = A,
    we have PÂ² = I - 2A + A = I - A = P. -/
axiom FisherOrthogonalProjector_idempotent (RF : RegularizedFisher n)
    (S : ConsolidatedSubspace n k)
    (F_reg_inv : Matrix (Fin n) (Fin n) â„)
    (Gram_inv : Matrix (Fin k) (Fin k) â„)
    (h_F_inv : F_reg_inv * RF.regularized = 1)
    (h_Gram_inv : let S_mat := SubspaceMatrix S
                  Gram_inv * (S_mat * F_reg_inv * S_matáµ€) = 1) :
    let P := FisherOrthogonalProjector RF S F_reg_inv Gram_inv
    P * P = P

/-- **AXIOM: Projected Vectors are Fisher-Orthogonal**

    Vectors projected by P_âŠ¥ are Fisher-orthogonal to the consolidated subspace S.
    This follows from the Fisher-feasibility of the projector output. -/
axiom FisherOrthogonalProjector_orthogonal (P : ParametricFamily n V) (Î¸ : Fin n â†’ â„)
    (RF : RegularizedFisher n) (S : ConsolidatedSubspace n k)
    (F_reg_inv : Matrix (Fin n) (Fin n) â„) (Gram_inv : Matrix (Fin k) (Fin k) â„)
    (h_F_inv : F_reg_inv * RF.regularized = 1)
    (h_Gram_inv : let S_mat := SubspaceMatrix S
                  Gram_inv * (S_mat * F_reg_inv * S_matáµ€) = 1)
    (h_RF : RF.F = FisherMatrix P Î¸)
    (v : Fin n â†’ â„) :
    let P_perp := FisherOrthogonalProjector RF S F_reg_inv Gram_inv
    IsFisherOrthogonal P Î¸ S (P_perp *áµ¥ v)

/-- **Projected Update Formula** (Main Theorem 4):

    The Fisher-orthogonal projection of the natural gradient direction g is:

    Î”Î¸_projected = P_âŠ¥ Â· g = (I - Fâ»Â¹S(SFâ»Â¹Sáµ€)â»Â¹Sáµ€) g

    This gives the closed-form solution to:
    min_Î”Î¸ â€–Î”Î¸ - gâ€–Â²_F  subject to  âŸ¨Î”Î¸, sâŸ©_F = 0 for all s âˆˆ S

    **This is the CONTROL LAW**: Given a gradient g, compute the
    Fisher-orthogonal projected update using matrix operations. -/
theorem projected_update_formula (P : ParametricFamily n V) (Î¸ : Fin n â†’ â„)
    (RF : RegularizedFisher n) (S : ConsolidatedSubspace n k)
    (F_reg_inv : Matrix (Fin n) (Fin n) â„) (Gram_inv : Matrix (Fin k) (Fin k) â„)
    (h_F_inv : F_reg_inv * RF.regularized = 1)
    (h_Gram_inv : let S_mat := SubspaceMatrix S
                  Gram_inv * (S_mat * F_reg_inv * S_matáµ€) = 1)
    (h_RF : RF.F = FisherMatrix P Î¸)
    (g : Fin n â†’ â„) :
    let Î”Î¸ := (FisherOrthogonalProjector RF S F_reg_inv Gram_inv) *áµ¥ g
    IsFisherOrthogonal P Î¸ S Î”Î¸ :=
  FisherOrthogonalProjector_orthogonal P Î¸ RF S F_reg_inv Gram_inv h_F_inv h_Gram_inv h_RF g

/-! ## Part IV: KL Bounds for Fisher-Orthogonal Updates -/

/-- **KL Bound for Single Fisher-Orthogonal Step** (Main Theorem 2):

    If the update Î”Î¸ is Fisher-orthogonal to the consolidated subspace S,
    then the KL divergence on consolidated behaviors is bounded by the
    cross-term, which vanishes in the orthogonal case.

    Key insight: Fisher-orthogonality means Î”Î¸áµ€ F s = 0 for all s âˆˆ S.
    So the "effective" change in the S-directions is zero at first order. -/
theorem Fisher_orthogonal_KL_bound (P : ParametricFamily n V) (Î¸ Î”Î¸ : Fin n â†’ â„)
    (S : ConsolidatedSubspace n k) (h_orth : IsFisherOrthogonal P Î¸ S Î”Î¸) :
    âˆ€ i : Fin k, FisherInner P Î¸ Î”Î¸ (S.basis i) = 0 :=
  h_orth

/-! ## Part V: No-Forgetting Horizon -/

/-- **Learning Step**: A single parameter update step. -/
structure LearningStep (n : â„•) where
  /-- Current parameters -/
  Î¸ : Fin n â†’ â„
  /-- Update direction -/
  Î”Î¸ : Fin n â†’ â„
  /-- Step size -/
  Î· : â„
  /-- Step size is positive -/
  Î·_pos : 0 < Î·

/-- **Learning Trajectory**: A sequence of K learning steps. -/
def LearningTrajectory (n K : â„•) := Fin K â†’ LearningStep n

/-- Total parameter change along a trajectory. -/
def totalChange {K : â„•} (traj : LearningTrajectory n K) : Fin n â†’ â„ :=
  fun i => âˆ‘ k : Fin K, (traj k).Î· * (traj k).Î”Î¸ i

/-- Sum of squared step norms along trajectory. -/
def sumSquaredSteps {K : â„•} (traj : LearningTrajectory n K) : â„ :=
  âˆ‘ k : Fin K, (traj k).Î·^2 * paramNormSq (traj k).Î”Î¸

/-- **No-Forgetting Horizon** (Main Theorem 5):

    If all steps are Fisher-orthogonal to the consolidated subspace S,
    then the accumulated KL drift on consolidated behaviors is bounded:

    KL(p_{Î¸_0} â€– p_{Î¸_K}) â‰¤ C Â· Î£â‚– Î·â‚–Â² â€–Î”Î¸â‚–â€–Â² Â· Î»_max(F)

    where Î»_max(F) is the largest eigenvalue of the Fisher matrix.

    This is the **learning-side sibling of trajectory_closure_bound**.

    **Physical interpretation**:
    - Îµ = average defect per step (â‰ˆ Î·Â² â€–Î”Î¸â€–Â² Î»_max)
    - K = number of steps
    - Total drift â‰¤ K Â· Îµ
    - Validity horizon T* = 1/Îµ gives "how long until we forget"

**AXIOM: No-Forgetting Horizon Bound (Riemannian Path Boundedness)**

    For Fisher-orthogonal learning trajectories, accumulated KL drift is bounded
    by the sum of squared step sizes.

    **Mathematical content**: The bound follows from:
    1. KL-Fisher local bound: each step contributes O(Î·Â² â€–Î”Î¸â€–Â²)
    2. Fisher-orthogonality: first-order drift in S-directions vanishes
    3. **Riemannian path integral bound** (NOT triangle inequality for KL):
       In the small-step regime, KL â‰ˆ Â½ dÂ²_Fisher, and squared Fisher distance
       along a quasi-geodesic path satisfies:
         dÂ²(p_0, p_K) â‰¤ C Â· Î£_k dÂ²(p_k, p_{k+1})
       This is the "quasi-geodesic" assumption: the learning trajectory does not
       take large detours in parameter space.

    **Domain of validity**: Small steps (Î· â†’ 0), smooth parametric families.
    This selects the "thermodynamic limit" where Riemannian geometry applies.

    **WARNING**: KL divergence is NOT a metric and does NOT satisfy the triangle
    inequality globally. This axiom is valid only in the small-step Riemannian regime.

    The constant C depends on eigenvalue bounds of the Fisher matrix. -/
axiom no_forgetting_horizon_bound {K : â„•} [NeZero K] (P : ParametricFamily n V)
    (traj : LearningTrajectory n K) (S : ConsolidatedSubspace n k)
    (h_orth : âˆ€ m : Fin K, IsFisherOrthogonal P (traj m).Î¸ S (traj m).Î”Î¸) :
    KL_divergence (P.p (traj âŸ¨0, Nat.pos_of_neZero KâŸ©).Î¸)
                  (P.p ((traj âŸ¨0, Nat.pos_of_neZero KâŸ©).Î¸ + totalChange traj)) â‰¤
      sumSquaredSteps traj

/-- **THEOREM: No-Forgetting Horizon (with explicit constant)**

    Accumulated KL drift is bounded by C times the sum of squared steps. -/
theorem no_forgetting_horizon {K : â„•} [NeZero K] (P : ParametricFamily n V)
    (traj : LearningTrajectory n K) (S : ConsolidatedSubspace n k)
    (h_orth : âˆ€ m : Fin K, IsFisherOrthogonal P (traj m).Î¸ S (traj m).Î”Î¸) :
    âˆƒ C : â„, 0 â‰¤ C âˆ§
      KL_divergence (P.p (traj âŸ¨0, Nat.pos_of_neZero KâŸ©).Î¸)
                    (P.p ((traj âŸ¨0, Nat.pos_of_neZero KâŸ©).Î¸ + totalChange traj)) â‰¤
        C * sumSquaredSteps traj := by
  use 1
  constructor
  Â· linarith
  Â· simp only [one_mul]
    exact no_forgetting_horizon_bound P traj S h_orth

/-- **Validity Horizon for Learning**: Time T* until accumulated drift exceeds threshold.

    If each step has "defect" Îµ = Î·Â² â€–Î”Î¸â€–Â² Î»_max(F), then:
    - After K steps: total drift â‰¤ K Â· Îµ
    - For drift threshold Î´: K* = Î´/Îµ steps until forgetting

    This parallels `validity_horizon` from ValidityHorizon.lean. -/
def learning_validity_horizon (Îµ Î´ : â„) (hÎµ : 0 < Îµ) : â„• :=
  Nat.ceil (Î´ / Îµ)

/-- The validity horizon gives the bound on number of safe steps. -/
theorem learning_validity_horizon_bound (Îµ Î´ : â„) (hÎµ : 0 < Îµ) (hÎ´ : 0 < Î´)
    (K : â„•) (hK : K â‰¤ learning_validity_horizon Îµ Î´ hÎµ) :
    (K : â„) * Îµ â‰¤ Î´ + Îµ := by
  unfold learning_validity_horizon at hK
  have h_ceil := Nat.le_ceil (Î´ / Îµ)
  have h_ceil_bound : (Nat.ceil (Î´ / Îµ) : â„) â‰¤ Î´ / Îµ + 1 := by
    have := Nat.ceil_lt_add_one (div_nonneg (le_of_lt hÎ´) (le_of_lt hÎµ))
    linarith
  calc (K : â„) * Îµ
      â‰¤ â†‘(Nat.ceil (Î´ / Îµ)) * Îµ := by
        apply mul_le_mul_of_nonneg_right (Nat.cast_le.mpr hK) (le_of_lt hÎµ)
    _ â‰¤ (Î´ / Îµ + 1) * Îµ := by
        apply mul_le_mul_of_nonneg_right h_ceil_bound (le_of_lt hÎµ)
    _ = Î´ + Îµ := by field_simp

/-! ## Part VI: Connection to SGC Defect Operator

**Bridge to SGC**: The Fisher-orthogonal projector P_âŠ¥ is analogous to
the SGC defect operator D = (I - Î ) L Î .

| Learning (Information Geometry) | Dynamics (SGC)              |
|---------------------------------|-----------------------------|
| Parameter space â„â¿              | Function space V â†’ â„        |
| Fisher metric F(Î¸)              | Ï€-weighted LÂ² metric        |
| Consolidated subspace S         | Coarse (block-constant) Î    |
| Fisher projection P_âŠ¥           | Complement projector (I-Î )  |
| KL drift per step               | Defect â€–Dâ€–                  |
| No-forgetting horizon           | Validity horizon T* = 1/Îµ  |

The key parallel: both measure "leakage" from a protected subspace.
-/

/-- **Leakage Defect for Learning**: Analogous to DefectOperator.
    Measures how much an update "leaks" into the consolidated subspace. -/
def LearningDefect (P : ParametricFamily n V) (Î¸ : Fin n â†’ â„)
    (S : ConsolidatedSubspace n k) (Î”Î¸ : Fin n â†’ â„) : â„ :=
  âˆ‘ i : Fin k, (FisherInner P Î¸ Î”Î¸ (S.basis i))^2

/-- Zero defect iff Fisher-orthogonal. -/
theorem LearningDefect_zero_iff_orthogonal (P : ParametricFamily n V) (Î¸ : Fin n â†’ â„)
    (S : ConsolidatedSubspace n k) (Î”Î¸ : Fin n â†’ â„) :
    LearningDefect P Î¸ S Î”Î¸ = 0 â†” IsFisherOrthogonal P Î¸ S Î”Î¸ := by
  unfold LearningDefect IsFisherOrthogonal
  constructor
  Â· intro h i
    have h_nonneg : âˆ€ j : Fin k, 0 â‰¤ (FisherInner P Î¸ Î”Î¸ (S.basis j))^2 :=
      fun j => sq_nonneg _
    have h_term := Finset.sum_eq_zero_iff_of_nonneg (fun j _ => h_nonneg j) |>.mp h i (Finset.mem_univ i)
    exact sq_eq_zero_iff.mp h_term
  Â· intro h
    apply Finset.sum_eq_zero
    intro i _
    simp only [h i, ne_eq, OfNat.ofNat_ne_zero, not_false_eq_true, zero_pow]

/-! ## Summary and Connections

This module establishes the **Information-Geometric Foundation for Learning**:

### Main Theorems

1. **KL_Fisher_local_bound**: KL â‰¤ Â½ Î”Î¸áµ€ F Î”Î¸ + O(â€–Î”Î¸â€–Â³)
   - "The metric controls drift"
   - Foundation for all subsequent bounds

2. **Fisher_orthogonal_KL_bound**: Orthogonal updates â†’ bounded KL change
   - First-order effects vanish
   - Only second-order accumulation

3. **projected_update_formula**: Closed-form P_âŠ¥ = I - Fâ»Â¹Sáµ€(SFâ»Â¹Sáµ€)â»Â¹S
   - Explicit "update operator"
   - Analogous to (I-Î )LÎ  in SGC

4. **no_forgetting_horizon**: Accumulated KL â‰¤ C Â· Î£ Î·Â² â€–Î”Î¸â€–Â²
   - Learning-side sibling of trajectory_closure_bound
   - Validity horizon for learned skills

### Connections Identified

**To Spiking Neural Networks**:
- Fisher metric â†” Spike timing precision
- Score function â†” Spike-triggered average
- Fisher-orthogonal updates â†” STDP rules that preserve consolidated patterns

**To Thermodynamic Computing**:
- KL divergence â†” Thermodynamic work (Jarzynski equality)
- Fisher metric â†” Thermodynamic length (Crooks fluctuation theorem)
- No-forgetting horizon â†” Thermodynamic irreversibility bound

**To SGC Framework**:
- LearningDefect â†” DefectOperator
- Consolidated subspace â†” Coarse partition
- Validity horizon â†” trajectory_closure_bound

-/

end SGC.InformationGeometry.FisherKL

end
