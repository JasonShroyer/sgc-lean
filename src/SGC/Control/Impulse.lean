/-
Copyright (c) 2025 SGC Project. All rights reserved.
Released under Apache 2.0 license as described in the file LICENSE.
Authors: SGC Formalization Team

# Impulsive Control: Thermodynamic Spiking

This module formalizes the **optimal control problem** for maintaining a valid
effective theory over time. The key insight: when effective theories have finite
validity horizons (T* = 1/Îµ), the optimal strategy is **impulsive control**â€”
discrete resets (spikes) rather than continuous adjustments.

## Physical Motivation

An effective theory (coarse-grained model) accumulates error over time:
- **Continuous dissipation**: Running an imperfect model generates heat/error
- **Validity horizon**: After time T* = 1/Îµ, the model becomes unreliable

The system has two choices:
1. **Continuous control**: Constantly fight the error (expensive, inefficient)
2. **Impulsive control**: Let error accumulate, then reset (spike)

**Claim**: Impulsive control is optimal. This is the physics of "when to think."

## The Thermodynamic Action

The total cost (Action) of a control policy Ï€ over horizon [0,T] is:

    S[Ï€] = ğ”¼[ âˆ«â‚€áµ€ |Defect(t)|Â² dt + Î» Â· N_spikes ]

where:
- First term: Continuous dissipation (running cost of imperfect prediction)
- Second term: Discrete work (cost of renormalization/reset)
- Î»: Spike cost parameter (metabolic cost of "thinking")

## Main Result (Conjectured)

The optimal policy is a **threshold policy**: Fire (spike) when |Defect(t)| â‰¥ Î¸*.

The optimal threshold Î¸* minimizes the average Action per cycle:
    Î¸* = argmin [ (Î¸Â²Â·Ï„(Î¸) + Î») / Ï„(Î¸) ]

where Ï„(Î¸) is the expected first-passage time to threshold Î¸.

## Connection to Neuroscience

This formalizes the "spiking neuron" as a thermodynamic regulator:
- **Membrane potential** â†” Accumulated defect
- **Firing threshold** â†” Optimal reset point Î¸*
- **Action potential** â†” Renormalization spike (reset to valid model)
- **Refractory period** â†” Post-spike validity window

## References

- Friston (2019): Free energy principle
- Rao & Ballard (1999): Predictive coding
- SGC Observables.ValidityHorizon: Finite horizon T* = 1/Îµ
- SGC Thermodynamics.DoobMeyer: Martingale decomposition

## Design Philosophy

Following SGC constraints:
1. **Discrete time** - Align with DoobMeyer framework
2. **Fintype state space** - Explicit sums, no measure theory
3. **Axiom transparency** - Optimization claims are explicit axioms/conjectures
-/

import SGC.Observables.ValidityHorizon
import SGC.Observables.EnergyUnification
import SGC.Thermodynamics.DoobMeyer

noncomputable section

namespace SGC.Control

open Finset Matrix Real SGC.Observables SGC SGC.Approximate SGC.Spectral

variable {V : Type*} [Fintype V] [DecidableEq V] [Nontrivial V]

/-! ## 1. Impulse Policy: When to Reset -/

/-- An **Impulse Policy** is a decision rule that determines when to "fire" (reset).

    In discrete time, this is a function from time and accumulated state to {0, 1}:
    - 0 = continue running the effective theory
    - 1 = fire (reset/renormalize)

    **Physical interpretation**: The policy encodes "when should the system think?"
    A value of 1 means "the accumulated error is too high; reset the model."

    **Stopping time interpretation**: The first time the policy outputs 1 is a
    stopping time with respect to the natural filtration. -/
structure ImpulsePolicy (V : Type*) where
  fire : â„• â†’ (V â†’ â„) â†’ Bool

/-- A **Threshold Policy** fires when the defect exceeds a threshold.

    This is the conjectured optimal form: fire when |Defect| â‰¥ Î¸. -/
def ThresholdPolicy (Î¸ : â„) (L : Matrix V V â„) (P : Partition V)
    (pi_dist : V â†’ â„) (hÏ€ : âˆ€ v, 0 < pi_dist v) : ImpulsePolicy V where
  fire := fun _ _state =>
    let defect := opNorm_pi pi_dist hÏ€ (DefectOperator L P pi_dist hÏ€)
    defect â‰¥ Î¸

/-- The **null policy** never fires. Represents "never reset."

    This is suboptimal: the effective theory eventually becomes invalid. -/
def NullPolicy : ImpulsePolicy V where
  fire := fun _ _ => false

/-- The **always policy** fires every step. Represents "continuous control."

    This is suboptimal: too much spike cost without benefit. -/
def AlwaysPolicy : ImpulsePolicy V where
  fire := fun _ _ => true

/-! ## 2. Thermodynamic Action: The Cost Functional -/

/-- **Running Cost**: The instantaneous cost of prediction error.

    At each time step, the system pays a cost proportional to |Defect|Â².
    This is the "heat" generated by running an imperfect model. -/
def RunningCost (L : Matrix V V â„) (P : Partition V) (pi_dist : V â†’ â„)
    (hÏ€ : âˆ€ v, 0 < pi_dist v) : â„ :=
  DefectNormSquared L P pi_dist hÏ€

/-- **Spike Cost**: The fixed cost of performing a reset/renormalization.

    Parameter Î» > 0 represents the metabolic cost of "thinking."
    - High Î»: Spikes are expensive â†’ fire less often â†’ tolerate more error
    - Low Î»: Spikes are cheap â†’ fire more often â†’ maintain low error -/
def SpikeCost (spikeCost : â„) (fired : Bool) : â„ :=
  if fired then spikeCost else 0

/-- **Thermodynamic Action** over a finite horizon [0, T].

    S[Ï€] = Î£â‚œâ‚Œâ‚€áµ€â»Â¹ [ RunningCost(t) + SpikeCost(t) ]

    This is the total cost of operating under policy Ï€.
    The optimal policy minimizes this action.

    **Note**: This is the discrete-time analog of the path integral:
    S[Ï€] = âˆ«â‚€áµ€ |Defect(t)|Â² dt + Î» Â· N_spikes -/
def ThermodynamicAction (L : Matrix V V â„) (P : Partition V) (pi_dist : V â†’ â„)
    (hÏ€ : âˆ€ v, 0 < pi_dist v) (spikeCost : â„) (policy : ImpulsePolicy V)
    (trajectory : â„• â†’ V â†’ â„) (T : â„•) : â„ :=
  âˆ‘ t âˆˆ Finset.range T,
    (RunningCost L P pi_dist hÏ€ + SpikeCost spikeCost (policy.fire t (trajectory t)))

/-- **Average Action Rate**: Action per unit time.

    For ergodic analysis, we care about the long-run average:
    Ï[Ï€] = lim_{Tâ†’âˆ} S[Ï€] / T

    A policy is optimal if it minimizes this rate. -/
def AverageActionRate (L : Matrix V V â„) (P : Partition V) (pi_dist : V â†’ â„)
    (hÏ€ : âˆ€ v, 0 < pi_dist v) (spikeCost : â„) (policy : ImpulsePolicy V)
    (trajectory : â„• â†’ V â†’ â„) (T : â„•) : â„ :=
  ThermodynamicAction L P pi_dist hÏ€ spikeCost policy trajectory T / T

/-! ## 3. First Passage Time: When Does Defect Hit Threshold? -/

/-- **First Passage Time** to threshold Î¸.

    Ï„(Î¸) = inf { t : |Defect(t)| â‰¥ Î¸ }

    For a threshold policy, this is the time between spikes.
    The optimal threshold balances:
    - Waiting longer (larger Ï„) â†’ more accumulated running cost
    - Waiting shorter (smaller Ï„) â†’ more frequent spike costs -/
def FirstPassageTime (Î¸ : â„) (defect_trajectory : â„• â†’ â„) : â„• :=
  Nat.find (âŸ¨0, by simpâŸ© : âˆƒ n, n = 0 âˆ¨ |defect_trajectory n| â‰¥ Î¸)

/-- **Expected First Passage Time** (parametric).

    ğ”¼[Ï„(Î¸)] depends on the dynamics of the defect process.
    For Brownian-like defect growth: ğ”¼[Ï„(Î¸)] ~ Î¸Â²/ÏƒÂ²

    This is axiomatized since proving it requires stochastic calculus. -/
axiom expected_first_passage_time (Î¸ Ïƒ : â„) (hÎ¸ : 0 < Î¸) (hÏƒ : 0 < Ïƒ) :
  âˆƒ Ï„_mean : â„, Ï„_mean > 0 âˆ§ Ï„_mean = Î¸^2 / Ïƒ^2

/-! ## 4. The Optimal Threshold Conjecture -/

/-- **Cycle Cost**: Total cost per spike-to-spike cycle.

    For a threshold policy with threshold Î¸:
    - Running cost accumulates: âˆ«â‚€^Ï„ |Defect(t)|Â² dt â‰ˆ (Î¸Â²/3) Â· Ï„
    - Plus one spike cost: Î»

    Total cycle cost: C(Î¸) = (Î¸Â²/3) Â· Ï„(Î¸) + Î» -/
def CycleCost (Î¸ Ï„ spikeCost : â„) : â„ :=
  (Î¸^2 / 3) * Ï„ + spikeCost

/-- **Average Rate for Threshold Policy**:

    Ï(Î¸) = CycleCost(Î¸) / Ï„(Î¸) = Î¸Â²/3 + Î»/Ï„(Î¸)

    Minimizing Ï(Î¸) gives the optimal threshold. -/
def ThresholdAverageRate (Î¸ Ï„ spikeCost : â„) : â„ :=
  CycleCost Î¸ Ï„ spikeCost / Ï„

/-- **Optimal Threshold** (Structure Definition).

    Î¸* is optimal if it minimizes the average action rate among all threshold policies.

    **Conjecture**: Î¸* = (3Î»ÏƒÂ²)^(1/4) where ÏƒÂ² is the defect diffusion rate.

    This structure packages the claim that a specific Î¸ is optimal. -/
structure IsOptimalThreshold (Î¸ : â„) (spikeCost Ïƒ : â„) : Prop where
  threshold_pos : 0 < Î¸
  spike_cost_pos : 0 < spikeCost
  diffusion_pos : 0 < Ïƒ
  minimizes_rate : âˆ€ Î¸' : â„, 0 < Î¸' â†’
    let Ï„ := Î¸^2 / Ïƒ^2
    let Ï„' := Î¸'^2 / Ïƒ^2
    ThresholdAverageRate Î¸ Ï„ spikeCost â‰¤ ThresholdAverageRate Î¸' Ï„' spikeCost

/-- **Optimal Threshold Formula** (Axiom/Conjecture).

    The optimal firing threshold is:
        Î¸* = (3Î»ÏƒÂ²)^(1/4)

    **Derivation** (informal):
    - Average rate: Ï(Î¸) = Î¸Â²/3 + Î»ÏƒÂ²/Î¸Â²
    - Set dÏ/dÎ¸ = 0: 2Î¸/3 - 2Î»ÏƒÂ²/Î¸Â³ = 0
    - Solve: Î¸â´ = 3Î»ÏƒÂ², so Î¸* = (3Î»ÏƒÂ²)^(1/4)

    **Physical interpretation**:
    - High spike cost Î» â†’ higher threshold â†’ fire less often
    - High diffusion Ïƒ â†’ lower threshold â†’ fire before defect grows too large -/
axiom optimal_threshold_formula (spikeCost Ïƒ : â„)
    (hsc : 0 < spikeCost) (hÏƒ : 0 < Ïƒ) :
    let Î¸_star := (3 * spikeCost * Ïƒ^2) ^ (1/4 : â„)
    IsOptimalThreshold Î¸_star spikeCost Ïƒ

/-! ## 5. Threshold Optimality: Main Structural Result -/

/-- **Threshold Policies are Optimal** (Axiom).

    Among all impulse policies, threshold policies minimize the average action rate.

    **Why this is deep**: This is an instance of the general principle that
    optimal stopping problems with monotone payoffs have threshold solutions.
    The formal proof requires:
    - Hamilton-Jacobi-Bellman equation
    - Verification theorem for optimal stopping
    - Convexity of the value function

    We axiomatize this structural result. -/
axiom threshold_policy_optimal (L : Matrix V V â„) (P : Partition V)
    (pi_dist : V â†’ â„) (hÏ€ : âˆ€ v, 0 < pi_dist v) (spikeCost : â„) (hsc : 0 < spikeCost) :
    âˆƒ Î¸ : â„, Î¸ > 0 âˆ§ âˆ€ (policy : ImpulsePolicy V) (trajectory : â„• â†’ V â†’ â„) (T : â„•),
    AverageActionRate L P pi_dist hÏ€ spikeCost (ThresholdPolicy Î¸ L P pi_dist hÏ€) trajectory T â‰¤
    AverageActionRate L P pi_dist hÏ€ spikeCost policy trajectory T

/-! ## 6. Connection to Validity Horizon -/

/-- **Validity Horizon as Threshold**.

    The validity horizon T* = 1/Îµ provides a natural threshold:
    when t > T*, the effective theory is invalid.

    **Claim**: The optimal threshold Î¸* corresponds to firing before T*. -/
def ValidityThreshold (Îµ : â„) (hÎµ : 0 < Îµ) : â„ := 1 / Îµ

/-- **Threshold-Horizon Consistency**.

    For the optimal threshold policy, the expected first passage time
    equals the validity horizon: ğ”¼[Ï„(Î¸*)] â‰ˆ T* = 1/Îµ.

    This connects control theory back to the Observables pillar. -/
axiom threshold_horizon_consistency (Îµ spikeCost Ïƒ : â„)
    (hÎµ : 0 < Îµ) (hsc : 0 < spikeCost) (hÏƒ : 0 < Ïƒ) :
    let Î¸_star := (3 * spikeCost * Ïƒ^2) ^ (1/4 : â„)
    let Ï„_star := Î¸_star^2 / Ïƒ^2
    âˆƒ C : â„, C > 0 âˆ§ |Ï„_star - 1/Îµ| â‰¤ C * (spikeCost * Ïƒ^2)^(1/2 : â„)

/-! ## 7. Non-Reversible Extension: When to Leave Equilibrium -/

/-- **Reversibility Detector**.

    The system may need to spike precisely when it drifts out of the reversible sector.
    A "reversibility defect" measures departure from self-adjointness.

    â€–L - Lâ€ â€–_Ï€ measures non-normality.

    **Conjecture**: Optimal spikes occur when reversibility defect exceeds threshold. -/
def ReversibilityDefect (L : Matrix V V â„) (pi_dist : V â†’ â„) : â„ :=
  âˆ‘ v, âˆ‘ w, pi_dist v * |L v w - L w v * (pi_dist w / pi_dist v)|

/-- **Fire on Non-Reversibility** policy.

    This policy fires when the system becomes "too non-reversible."
    Relevant for systems that should maintain detailed balance. -/
def NonReversibilityPolicy (Î¸_rev : â„) (L : Matrix V V â„) (pi_dist : V â†’ â„)
    (hÏ€ : âˆ€ v, 0 < pi_dist v) : ImpulsePolicy V where
  fire := fun _ _ =>
    ReversibilityDefect L pi_dist â‰¥ Î¸_rev

/-! ## 8. Physical Interpretation: The Spiking Neuron -/

/-- **Thermodynamic Neuron** bundles the key parameters.

    A neuron is characterized by:
    - `threshold`: Firing threshold Î¸*
    - `spike_cost`: Metabolic cost Î» of generating an action potential
    - `diffusion`: Rate Ïƒ at which membrane potential fluctuates
    - `reset_value`: Post-spike membrane potential (typically 0) -/
structure ThermodynamicNeuron where
  threshold : â„
  spike_cost : â„
  diffusion : â„
  reset_value : â„
  threshold_pos : 0 < threshold
  spike_cost_pos : 0 < spike_cost
  diffusion_pos : 0 < diffusion

/-- **Neuron fires optimally** if its threshold equals the optimal threshold.

    This is the central claim: biological neurons are thermodynamic regulators
    that minimize the action (free energy) via optimal threshold spiking. -/
def NeuronIsOptimal (n : ThermodynamicNeuron) : Prop :=
  n.threshold = (3 * n.spike_cost * n.diffusion^2) ^ (1/4 : â„)

/-- **Optimal Neuron Construction**.

    Given spike cost Î» and diffusion Ïƒ, construct the optimal neuron. -/
def optimalNeuron (spikeCost Ïƒ : â„) (hsc : 0 < spikeCost) (hÏƒ : 0 < Ïƒ) :
    ThermodynamicNeuron where
  threshold := (3 * spikeCost * Ïƒ^2) ^ (1/4 : â„)
  spike_cost := spikeCost
  diffusion := Ïƒ
  reset_value := 0
  threshold_pos := by
    apply Real.rpow_pos_of_pos
    apply mul_pos
    apply mul_pos
    Â· linarith
    Â· exact hsc
    Â· exact sq_pos_of_pos hÏƒ
  spike_cost_pos := hsc
  diffusion_pos := hÏƒ

theorem optimal_neuron_is_optimal (spikeCost Ïƒ : â„) (hsc : 0 < spikeCost) (hÏƒ : 0 < Ïƒ) :
    NeuronIsOptimal (optimalNeuron spikeCost Ïƒ hsc hÏƒ) := by
  unfold NeuronIsOptimal optimalNeuron
  rfl

end SGC.Control
